{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNFjCZnxW6zJzZLUEECPiGL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# üéØ Learning Objectives\n","\n","By the end of this notebook, you will be able to:\n","\n","- Understand the structure of the **MaFaulDa dataset** and its class hierarchy.  \n","- Download, extract, and organize multi-class datasets with **vibration and microphone recordings**.  \n","- Explore dataset metadata and create a **DataFrame of available files**.  \n","- Inspect and show top / bottom examples by signal length to illustrate variability.  \n","- Load and visualize sensor signals from CSV files, with **optional normalization** for fair comparison.  \n","- Compare signals from different classes in the **time domain** and overlay **rolling statistics** (mean/RMS).  \n","- Perform **spectrogram (time‚Äìfrequency) analysis** for selected channels.  \n","- Listen to **microphone recordings** and relate sound to operating conditions.  \n","- Prepare for feature extraction and ML tasks by automating metadata collection and basic signal summaries."],"metadata":{"id":"XX66lmVMum_K"}},{"cell_type":"code","source":["# ---- Imports ----\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import zipfile\n","import urllib.request\n","import ssl\n","import shutil\n","from urllib.parse import urljoin\n","from scipy.signal import spectrogram\n","from scipy.fft import fft, fftfreq\n","from IPython.display import Audio, display"],"metadata":{"id":"HLK0TXsZuo6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---- Define Dataset URLs ----\n","\n","dataset_urls = {\n","    \"Normal\": \"https://www02.smt.ufrj.br/~offshore/mfs/database/mafaulda/normal.zip\",\n","    \"Horizontal Misalignment\": \"https://www02.smt.ufrj.br/~offshore/mfs/database/mafaulda/horizontal-misalignment.zip\",\n","    # \"Vertical Misalignment\": \"https://www02.smt.ufrj.br/~offshore/mfs/database/mafaulda/vertical-misalignment.zip\",\n","    # \"Imbalance\": \"https://www02.smt.ufrj.br/~offshore/mfs/database/mafaulda/imbalance.zip\",\n","    # \"Underhang Bearing\": \"https://www02.smt.ufrj.br/~offshore/mfs/database/mafaulda/underhang-bearing.zip\",\n","    # \"Overhang Bearing\": \"https://www02.smt.ufrj.br/~offshore/mfs/database/mafaulda/overhang-bearing.zip\",\n","}"],"metadata":{"id":"lv-pWyBVup6X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---- Dataset Source Configuration ----\n","\n","# Detect environment\n","try:\n","    import google.colab\n","    ON_COLAB = True\n","except ImportError:\n","    ON_COLAB = False\n","\n","# Set paths based on environment and source (‚ö†Ô∏è Update COURSE_PATH below if your folder has a different name or location)\n","if ON_COLAB:\n","    # Mount Google Drive if using Colab\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","\n","    # Base folder for this course on Google Drive\n","    COURSE_PATH = \"/content/drive/MyDrive/Industrial_ML_Course\"\n","else:\n","    # Offline / local computer\n","    # Adjust COURSE_PATH to your local folder\n","    COURSE_PATH = r\"D:\\Industrial_ML_Course\"\n","\n","# Subfolders\n","DATASET_PATH = os.path.join(COURSE_PATH, \"datasets/MaFaulDa\")\n","NOTEBOOK_PATH = os.path.join(COURSE_PATH, \"notebooks\")\n","\n","# Ensure directories exist\n","os.makedirs(DATASET_PATH, exist_ok=True)\n","os.makedirs(NOTEBOOK_PATH, exist_ok=True)\n","\n","print(\"Environment:\", \"Colab\" if ON_COLAB else \"Local\")\n","print(\"Course Path:\", COURSE_PATH)\n","print(\"Dataset Path:\", DATASET_PATH)"],"metadata":{"id":"ZqMmWVebvIDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---- Download and Extract All Classes ----\n","\n","# SSL context to ignore certificate issues\n","ssl_context = ssl._create_unverified_context()\n","\n","def download_and_extract(cls, url, dataset_path=DATASET_PATH):\n","    \"\"\"Download and extract a single MaFaulDa class dataset.\"\"\"\n","\n","    # Get folder name (remove .zip extension)\n","    folder_name = os.path.join(dataset_path, os.path.splitext(os.path.basename(url))[0])\n","\n","    if os.path.exists(folder_name):\n","        print(f\"[‚úî] {cls} folder already exists: {folder_name}\")\n","        return\n","\n","    zip_file = os.path.join(dataset_path, os.path.basename(url))\n","\n","    # Download zip file if not exists\n","    if not os.path.exists(zip_file):\n","        print(f\"[‚Üì] Downloading {cls} zip file ...\")\n","        with urllib.request.urlopen(url, context=ssl_context) as response, open(zip_file, 'wb') as out_file:\n","            out_file.write(response.read())\n","        print(f\"[‚úî] {cls} zip file downloaded.\")\n","    else:\n","        print(f\"[‚úî] {cls} zip file already exists: {zip_file}\")\n","\n","    # Extract zip file\n","    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n","        zip_ref.extractall(dataset_path)\n","    print(f\"[‚úî] {cls} zip file extracted to {folder_name}\")\n","\n","    # Cleanup zip file after successful extraction\n","    try:\n","        os.remove(zip_file)\n","        print(f\"[‚úó] {cls} zip file removed.\")\n","    except OSError as e:\n","        print(f\"[!] Warning: could not remove {zip_file}: {e}\")\n","\n","# Loop through all classes\n","for cls, url in dataset_urls.items():\n","    download_and_extract(cls, url)"],"metadata":{"id":"qvptl3jOvOR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---- Explore Files and Build Metadata ----\n","\n","# Classes come directly from dataset_urls keys (converted to lowercase for consistency)\n","classes = [cls.lower().replace(\" \", \"-\") for cls in dataset_urls.keys()]\n","metadata = []\n","\n","for cls in classes:\n","    class_path = os.path.join(DATASET_PATH, cls)\n","\n","    # Walk through all subfolders and collect CSV files\n","    for root, _, files in os.walk(class_path):\n","        for f in files:\n","            if f.endswith(\".csv\"):\n","                file_path = os.path.join(root, f)\n","\n","                # Collect dataset metadata (filename, class label, full path, relative subfolder)\n","                metadata.append({\n","                    \"file\": f,\n","                    \"class\": cls,\n","                    \"path\": file_path,\n","                    \"subfolder\": os.path.relpath(root, class_path)\n","                })\n","\n","# Convert to DataFrame\n","df_meta = pd.DataFrame(metadata)\n","\n","# Display a small sample\n","display(df_meta.sample(5, random_state=42))\n","print(f\"Total files: {len(df_meta)}\")\n","print(df_meta[\"class\"].value_counts())"],"metadata":{"id":"D8i-dQJF1otq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---- Load and Compare Two Sample Signals from Different Classes ----\n","\n","# Assign sensor names\n","sensor_names = [\n","    \"tachometer\",\n","    \"under_axial\", \"under_radial\", \"under_tangential\",\n","    \"over_axial\", \"over_radial\", \"over_tangential\",\n","    \"microphone\"\n","]\n","\n","# Pick two random samples from different classes\n","samples = df_meta.groupby(\"class\").sample(1, random_state=42).head(2)\n","\n","# Settings for plotting improvements\n","max_samples = 5000   # keep plot readable\n","normalize_for_plot = True   # option: normalize each plotted channel to [-1,1]\n","overlay_rolling = True      # option: overlay rolling mean/RMS\n","rolling_window = 200        # samples\n","\n","fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n","\n","for i, (_, sample) in enumerate(samples.iterrows()):\n","    # Load CSV file (no header ‚Üí force header=None)\n","    df_signal = pd.read_csv(sample[\"path\"], header=None)\n","\n","    # Assign sensor names\n","    df_signal.columns = sensor_names\n","\n","    print(f\"Sample {i+1}: {sample['file']}\")\n","    print(f\"   Class: {sample['class']}\")\n","    print(f\"   Subfolder: {sample['subfolder']}\")\n","    print(f\"   Shape: {df_signal.shape}\")\n","    print(\"\\n\")\n","\n","    # Subset for plotting\n","    idx_end = min(max_samples, df_signal.shape[0])\n","    tach = df_signal['tachometer'].values[:idx_end]\n","    accel = df_signal['under_radial'].values[:idx_end]\n","    mic = df_signal['microphone'].values[:idx_end]\n","\n","    # Normalization function\n","    def norm_sig(x):\n","        x = x.astype(float)\n","        m = np.max(np.abs(x))\n","        if m == 0:\n","            return x\n","        return x / m\n","\n","    if normalize_for_plot:\n","        tach_plot = norm_sig(tach)\n","        accel_plot = norm_sig(accel)\n","        mic_plot = norm_sig(mic)\n","    else:\n","        tach_plot, accel_plot, mic_plot = tach, accel, mic\n","\n","    axes[i].plot(tach_plot, label=\"Tachometer\", alpha=0.9)\n","    axes[i].plot(accel_plot, label=\"Underhang Radial\", alpha=0.9)\n","    axes[i].plot(mic_plot, label=\"Microphone\", alpha=0.9)\n","\n","    # overlay rolling stats on microphone for emphasis (optional)\n","    if overlay_rolling:\n","        mic_series = pd.Series(mic_plot)\n","        rm = mic_series.rolling(window=rolling_window, min_periods=1).mean()\n","        rrms = mic_series.rolling(window=rolling_window, min_periods=1).apply(lambda x: np.sqrt(np.mean(x**2)))\n","        axes[i].plot(rm, label=\"Mic Rolling Mean\", color=\"k\", linewidth=1.5, linestyle='--')\n","        axes[i].plot(rrms, label=\"Mic Rolling RMS\", color=\"magenta\", linewidth=1.5, linestyle=':')\n","\n","    axes[i].set_title(f\"Sample {i+1} - Class: {sample['class']}\")\n","    axes[i].set_ylabel(\"Amplitude (normalized)\" if normalize_for_plot else \"Amplitude\")\n","    axes[i].legend(loc='upper right')\n","\n","axes[-1].set_xlabel(\"Time (samples)\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"mIPAEofMAMOZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---- Spectrogram (time‚Äìfrequency analysis) ----\n","\n","fs = 50000  # sampling frequency\n","\n","fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n","\n","for i, (_, sample) in enumerate(samples.iterrows()):\n","    # Load CSV file (no header ‚Üí force header=None)\n","    df_signal = pd.read_csv(sample[\"path\"], header=None)\n","\n","    # Assign sensor names\n","    df_signal.columns = sensor_names\n","\n","    # Pick the microphone channel (last column)\n","    signal = df_signal[\"microphone\"].values[:max_samples]\n","\n","    # Calculate spectrogram\n","    # nperseg: window length (smaller -> better time resolution; larger -> better freq resolution)\n","    # noverlap: overlap between windows\n","    f, t, Sxx = spectrogram(signal, fs=fs, nperseg=1024, noverlap=512)\n","\n","    # Plot spectrogram\n","    pcm = axes[i].pcolormesh(t, f, 10 * np.log10(Sxx + 1e-12), shading='gouraud')  # small eps for numerical stability\n","    fig.colorbar(pcm, ax=axes[i], label=\"Power/Frequency (dB/Hz)\")\n","\n","    axes[i].set_title(f\"Spectrogram of Microphone Channel - Class: {sample['class']}\")\n","    axes[i].set_ylabel(\"Frequency [Hz]\")\n","    axes[i].set_xlabel(\"Time [s]\")\n","    axes[i].set_ylim(0, 5000)  # limit to lower frequencies if needed\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"I5kEX93tBgmu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---- Listen to the microphone channels ----\n","\n","for _, sample in samples.iterrows():\n","    # Load CSV file (no header ‚Üí force header=None)\n","    df_signal = pd.read_csv(sample[\"path\"], header=None)\n","\n","    # Assign sensor names\n","    df_signal.columns = sensor_names\n","\n","    # Pick microphone channel\n","    mic_signal = df_signal['microphone'].values.astype(float)\n","\n","    # Normalize to avoid clipping (guard against zeros)\n","    max_abs = np.max(np.abs(mic_signal))\n","    if max_abs == 0:\n","        mic_norm = mic_signal\n","    else:\n","        mic_norm = mic_signal / max_abs\n","\n","    print(f\"Class: {sample['class']} | File: {os.path.basename(sample['path'])}\")\n","    display(Audio(mic_norm, rate=fs))"],"metadata":{"id":"vVFFoxptCFK2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üöÄ Explore More! (Guided Exercises)\n","\n","1. **Channel Comparison**  \n","   - Compare signals from different channels (tachometer, accelerometers, microphone) for the same sample.  \n","   - Try plotting both with and without normalization. Which view makes differences between classes more visible?  \n","\n","2. **Spectrogram Parameter Tuning**  \n","   - Experiment with `nperseg` and `noverlap`.  \n","   - Recall: smaller `nperseg` ‚Üí better time resolution; larger `nperseg` ‚Üí better frequency resolution.  \n","   - Which settings highlight differences between healthy and faulty cases most clearly?  \n","\n","3. **Time-Domain Feature Extraction (Exploration)**\n","   - Using a **small subset of files and channels**, compute basic features for each signal:\n","     - `mean`, `std`, `RMS`, `peak-to-peak`, `skewness`, `kurtosis`.\n","   - Add these features as columns in a **mini DataFrame** for inspection.\n","   - Explore differences across channels and classes:\n","     - Which channels show the largest variability?\n","     - Are certain features more sensitive to faults or specific classes?\n","   - Purpose: **understand features and their interpretability** on a manageable scale.\n","\n","4. **Rolling Statistics**  \n","   - Apply rolling averages or RMS with different window sizes (e.g., 50, 200, 1000 samples).  \n","   - How does the amount of smoothing affect the ability to spot patterns or anomalies?  \n","\n","5. **Automation Challenge (Scaling Up)**\n","   - Write a function that automatically processes **all files and channels** in the dataset.\n","   - For each **file √ó channel** pair, compute the same features as in Exercise 3.\n","   - Build a **complete feature matrix**:\n","     - Rows = individual signals (file √ó channel)\n","     - Columns = extracted features\n","     - Include metadata: `file`, `class`, `channel`\n","   - Inspect the resulting table:\n","     - Are there clear differences between channels or classes?\n","     - Which channels or features are most informative for ML models?\n","   - Purpose: **scale up the manual exploration from Exercise 3** to a dataset-wide feature extraction for later classification."],"metadata":{"id":"o72vPIQBOuDc"}}]}